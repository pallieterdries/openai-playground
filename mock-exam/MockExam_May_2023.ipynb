{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c48b0acd",
   "metadata": {},
   "source": [
    "# Large omics mock exam\n",
    "\n",
    "The official exam will take 3 hours. This test exam only 2 hours. Questions will be similar to this exam, but the official exam will have a number of additional theoretical questions. \n",
    "\n",
    "**Note:** \n",
    "\n",
    "* The exam is open book, open internet. However the use of any communication tool (chat, mail, etc) is strictly forbidden - you will automatically fail the exam.\n",
    "* You are allowed to use Github during the exam - but do not post any comments without consulting me (for example to correct an obvious mistake).\n",
    "* For all questions - please provide comments describing what you are plannning to do. Even if you get stuck - add comments describing the followup steps - If I understand your thought process - I can still give you a partial score.\n",
    "\n",
    "You will be expected to upload the following files to a Toledo Mock Exam Assignment (the mock exam will not be graded - but you can upload anyway to practice. Please upload:\n",
    "\n",
    "* This ipython notebook with your answers. (download using `Jupyter menu / File / Download as / Notebook (.ipynb)`) \n",
    "* An HTML copy of this notebook (download using `Jupyter menu / File / Download as / HTML (.html)`) - Note you must zip this file prior to upload, Toledo does not allow html file uploads.\n",
    "* Exercise 1:\n",
    "    * Your new Snakemake file (`Snakefile`)\n",
    "    * `indels.0.png`\n",
    "* Exercise 3:\n",
    "    * Variant impact plots for NOTCH1 and OLFM1\n",
    "\n",
    "Do not leave uploading files to the last minute - the assignment will automatically close. You are allowed multiple uploads - last one counts.\n",
    "\n",
    "\n",
    "## Create and work in an work folder.\n",
    "\n",
    "Prior to starting the exam make sure you create a work folder:\n",
    "\n",
    "```\n",
    "mkdir -p $VSC_DATA/test_exam_2023\n",
    "cd $VSC_DATA/test_exam_2023\n",
    "```\n",
    "\n",
    "Subsequently, copy this jupyter notebook to that folder - and open it again in jupyter.\n",
    "\n",
    "Best of luck, Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3faba25",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "### Data required\n",
    "\n",
    "Copy the data files to your work folder:\n",
    "\n",
    "```\n",
    "cd $VSC_DATA/test_exam_2023 \n",
    "cp -r /staging/leuven/stg_00079/teaching/mock_exam/2023/* .\n",
    "```\n",
    "\n",
    "###  Terminal/Conda\n",
    "\n",
    "Do your (CPU intensive) command line work in a VSC interactive session.\n",
    "\n",
    "For **all** command line work (including snakemake) - make sure you use the correct conda environment by running the following in your shell:\n",
    "\n",
    "    export PATH=/staging/leuven/stg_00079/teaching/miniconda3/envs/large_omics_2023_b/bin:$PATH\n",
    "    \n",
    "You can check if you have the correct kernel loaded by running:\n",
    "\n",
    "    which python\n",
    "    \n",
    "Which should yield `/staging/leuven/stg_00079/teaching/miniconda3/envs/large_omics_2023_b/bin/python`\n",
    "\n",
    "\n",
    "### Jupyter\n",
    "\n",
    "Ensure you use the correct kernel for the jupyter work! You can confirm you have the correct kernel by running (in python):\n",
    "\n",
    "    import sys\n",
    "    sys.executable\n",
    "    \n",
    "Which should yield `/staging/leuven/stg_00079/teaching/miniconda3/envs/large_omics_2023_b/bin/python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3703e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a311a0d",
   "metadata": {},
   "source": [
    "### Import a few modules\n",
    "(do not forget to execute the cell below!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6167e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a83c32",
   "metadata": {},
   "source": [
    "## Question 1 - Snakemake\n",
    "\n",
    "In your exam folder you wil a snakemake folder containing the workflow definition (`snakemake/Snakefile`). The Snakefile is exactly the workflow we discussed during this course. The workflow has almost completely executed (except for the snpEff step).\n",
    "\n",
    "The objective of this question is to add a new analysis step to the Snakemake file.\n",
    "\n",
    "The Snakemake file will have to run [`bcftools stats`](https://samtools.github.io/bcftools/bcftools.html#stats) and subsequent [`plot-vcfstats`](https://samtools.github.io/bcftools/bcftools.html#plot-vcfstats) to create a number of plots visualizing a number statistics from the VCF file. \n",
    "\n",
    "**Note**:\n",
    "\n",
    " * You must add **a new [rule](https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html)** to the `Snakefile` - not adapt an existing rule!\n",
    " * Ensure the new rule gets automatically executed when running Snakemake without defining a rule.\n",
    " * Ensure the stats are executed on the annotated vcf file generated by the snpEff step.\n",
    " * Please upload your new `Snakefile` and the generated `indels.0.png` to the Toledo assignment.\n",
    " * Make sure all generated output end up in a dedicated subfolder (eg `060.stats`). Copy the output of `ls -lt` on the new snakemake stats output folder in the markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e9b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b919d64e-d0cf-4273-b08d-fb75a391b8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a324d803",
   "metadata": {},
   "source": [
    "## Question 2 - Extending the SNP database\n",
    "\n",
    "In the exam folder you will find a notebook called `ParseVCF.ipynb` that was used to create the database `exam.sqlite` - also in the exam folder. Check the `ParseVCF.ipynb` file to see how this database was created. In particular, note the snp identifier format that we use to link tables (in the `snp` column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d4b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dbfile = 'exam.sqlite'\n",
    "db = sqlite3.connect(dbfile)\n",
    "pd.read_sql('SELECT * FROM snp LIMIT 5', db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9007d9d2",
   "metadata": {},
   "source": [
    "In the exam folder you will also find a file called `dbsnp.tsv` which contains the dbSNP rs-ids for our vcf file. The first few lines look like this:\n",
    "\n",
    "    chrom  pos        ref  alt  dbsnp\n",
    "    chr9   127578816  C    T    rs4240419\n",
    "    chr9   127578974  A    G    rs4240420\n",
    "    chr9   127579080  A    G    rs4240421\n",
    "    chr9   127663498  C    T    rs7036307\n",
    "    chr9   127674824  G    T    None\n",
    "    chr9   127679143  G    T    None\n",
    "\n",
    "   \n",
    "Can you load the `dbsnp.tsv` file as a pandas DataFrame, create a SNP id in exactly the same format as in the rest of the database, and save this into a **new table** into the database?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112fec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First - create a pandas table with the data. This is easy\n",
    "# as pandas can read csv:\n",
    "\n",
    "dbsnp = pd.read_csv('dbsnp.tsv', sep=\"\\t\")\n",
    "\n",
    "# Important is to create a 'snp' column with an identifiers\n",
    "# of exactly the same format. There are many ways to do this:\n",
    "\n",
    "dbsnp['snp'] = dbsnp['chrom'].astype(str) \\\n",
    "        + \":\" + dbsnp['pos'].astype(str) \\\n",
    "        + \":\" + dbsnp['ref'] \\\n",
    "        + \":\" + dbsnp['alt'] \n",
    "\n",
    "# And save the table to your database (as we did for the other \n",
    "# tables as well)\n",
    "print('dbsnp records', \n",
    "      dbsnp.to_sql('dbsnp', db, if_exists='replace', index=False))\n",
    "\n",
    "# show the first few lines - to be sure everything is in order\n",
    "dbsnp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d7515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea77cc9",
   "metadata": {},
   "source": [
    "**Question:** With this new table, can you write a SQL query to find the dbSnp ID of the single HIGH impact variant in the `FAM166A` gene? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6769d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f5760",
   "metadata": {},
   "source": [
    "## Question 3 - Visualization\n",
    "\n",
    "Given the our annotated database in `exam.sqlite` with tables `snp`, `snp_call` and `snp_effect` (the database we created during class):\n",
    "\n",
    "Can you create a plot showing the distribution of effect types for a given gene name?\n",
    "\n",
    "* Please formulate this as a function with the name of the gene as an argument (expand the skeleton below)\n",
    "* Save the generated plot as a PNG image (using the correct `matplotlib` function!).\n",
    "* Create plots for the genes `NOTCH1` and `OLFM1`, upload the plots to the Toledo Assignment.\n",
    "* Some SNPs have multiple effects at the same time (for example: `splice_region_variant&intron_variant`) - you can plot these as they are - no need to separate them.\n",
    "* Note - read this github issue: https://github.com/I0U19A-Large-Omics/Q-A/issues/41 \n",
    "* Warning - if you think you damaged the sqlite database in the previous step - you can always get a fresh copy from: `/lustre1/project/stg_00079/teaching/mock_exam/exam.sqlite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c284894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dbfile = 'exam.sqlite'\n",
    "db = sqlite3.connect(dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cec9a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc638f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5684ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f9510e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "large_omics_2023",
   "language": "python",
   "name": "large_omics_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
